{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "from networkx.algorithms.community import k_clique_communities, girvan_newman\n",
    "from networkx import edge_betweenness_centrality as betweenness\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData = {\n",
    "    'product/productId': [],\n",
    "    'review/userId': [],\n",
    "    'review/profileName': [],\n",
    "    'review/helpfulness': [],\n",
    "    'review/score': [],\n",
    "    'review/time': [],\n",
    "    'review/summary': [],\n",
    "    'review/text': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the input dataset file and create a dictionary of input data with each column as key\n",
    "input_file = open('sample_data.txt', 'r')\n",
    "key_value = []\n",
    "for line in input_file:\n",
    "    if len(line.strip()) != 0:\n",
    "        key_value = line.split(':')\n",
    "        if key_value[0].strip() in inputData.keys():\n",
    "            inputData[key_value[0].strip()].append(key_value[1].strip())\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product/productId</th>\n",
       "      <th>review/userId</th>\n",
       "      <th>review/profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0/0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1/1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3/3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product/productId   review/userId               review/profileName  \\\n",
       "0        B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1        B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2        B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3        B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4        B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "  review/helpfulness review/score review/time         review/summary  \\\n",
       "0                1/1          5.0  1303862400  Good Quality Dog Food   \n",
       "1                0/0          1.0  1346976000      Not as Advertised   \n",
       "2                1/1          4.0  1219017600  \"Delight\" says it all   \n",
       "3                3/3          2.0  1307923200         Cough Medicine   \n",
       "4                0/0          5.0  1350777600            Great taffy   \n",
       "\n",
       "                                         review/text  \n",
       "0  I have bought several of the Vitality canned d...  \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  This is a confection that has been around a fe...  \n",
       "3  If you are looking for the secret ingredient i...  \n",
       "4  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe from the input data dictionary and split the dataframe into train and test sets\n",
    "train_df = pd.DataFrame.from_dict(inputData)\n",
    "# train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "#print(df.shape, train_df.shape, test_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product/productId</th>\n",
       "      <th>review/userId</th>\n",
       "      <th>review/profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>939</td>\n",
       "      <td>939</td>\n",
       "      <td>939</td>\n",
       "      <td>939</td>\n",
       "      <td>939</td>\n",
       "      <td>939</td>\n",
       "      <td>939</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>193</td>\n",
       "      <td>906</td>\n",
       "      <td>902</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>706</td>\n",
       "      <td>898</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A3PJZ8TU8FDQ1K</td>\n",
       "      <td>Jared Castle</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1334016000</td>\n",
       "      <td>Delicious!</td>\n",
       "      <td>I'm addicted to salty and tangy flavors, so wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>217</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>450</td>\n",
       "      <td>600</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product/productId   review/userId review/profileName  \\\n",
       "count                939             939                939   \n",
       "unique               193             906                902   \n",
       "top           B000G6RYNE  A3PJZ8TU8FDQ1K       Jared Castle   \n",
       "freq                 217               5                  5   \n",
       "\n",
       "       review/helpfulness review/score review/time review/summary  \\\n",
       "count                 939          939         939            939   \n",
       "unique                 65            5         706            898   \n",
       "top                   0/0          5.0  1334016000     Delicious!   \n",
       "freq                  450          600           5              8   \n",
       "\n",
       "                                              review/text  \n",
       "count                                                 939  \n",
       "unique                                                934  \n",
       "top     I'm addicted to salty and tangy flavors, so wh...  \n",
       "freq                                                    3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from train data\n",
    "# key -> product\n",
    "# value -> concatenated reviews by various users for the product\n",
    "# Finally extract list of unique produccts and concatenated reviews from the dictionary\n",
    "product_reviews_dict = {}\n",
    "for index, row in train_df.iterrows():\n",
    "    if row['product/productId'] in product_reviews_dict:\n",
    "        product_reviews_dict[row['product/productId']] = product_reviews_dict[row['product/productId']] + \" \" + row['review/text']\n",
    "    else:\n",
    "        product_reviews_dict[row['product/productId']] = row['review/text']\n",
    "products_list = list(product_reviews_dict.keys())\n",
    "reviews_list = list(product_reviews_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the review text using CountVectorizer to create a document term matrix (product vs words in review)\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(reviews_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 150)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce the dimensionality of document term matrix\n",
    "svd = TruncatedSVD(n_components=150, n_iter=5)\n",
    "X_red = svd.fit_transform(X)\n",
    "X_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an adjacency matrix for graph using kneighbors_graph with speciefied number of neighbors\n",
    "X_graph_adj = kneighbors_graph(X_red, 10, mode='distance', n_jobs=-1)\n",
    "# X_graph.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 193\n",
      "Number of edges: 1661\n",
      "Average degree:  17.2124\n"
     ]
    }
   ],
   "source": [
    "# Create a networkX graph from the adjacency matrix\n",
    "main_graph = nx.from_scipy_sparse_matrix(X_graph_adj)\n",
    "\n",
    "# Create a label mapping between products and indices created in the graph\n",
    "label_mapping = dict(zip(main_graph.nodes(), products_list))\n",
    "\n",
    "# Relabel the indices in the graph with product names \n",
    "main_graph = nx.relabel_nodes(main_graph, label_mapping)\n",
    "print(nx.info(main_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate pagerank for the nodes in a community within a graph\n",
    "def getPageRankOfCommunity(G, community_nodes):\n",
    "    community_graph = G.subgraph(community_nodes)\n",
    "    return nx.pagerank(community_graph, alpha=0.85, weight='weight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idenntify Communities using K-Clique community detection algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate K-Clique algorithm and get the communities \n",
    "k_clique = k_clique_communities(main_graph, 6)\n",
    "\n",
    "# Transform the communities obtained into a dictionary with\n",
    "# key -> communityId\n",
    "# value -> list of nodes in the community\n",
    "kc_dict = dict(enumerate(k_clique))\n",
    "\n",
    "# Create a dictionary with\n",
    "# key -> product\n",
    "# value -> Id of the community the product belongs to\n",
    "kc_product_comm_dict = {}\n",
    "for comm, products in kc_dict.items():\n",
    "    for product in products:\n",
    "        kc_product_comm_dict[product] = comm\n",
    "\n",
    "# Calculate pagerank for the nodes in each community and create a dictionary where\n",
    "# key -> communityId\n",
    "# value -> list of tuples (product, pagerank) sorted in descending order of pagerank\n",
    "kc_community_pagerank_dict = {}\n",
    "for comm, nodes in kc_dict.items():\n",
    "    page_rank_dict = getPageRankOfCommunity(main_graph, nodes)\n",
    "    kc_community_pagerank_dict[comm] = sorted(page_rank_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "# print(kc_community_pagerank_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify Communities using Girvan-Newman community detection algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to evaluate the most valuable edge considering the weights of the edges\n",
    "# then use the function in girvan newman algorith to remove the edge returned byb this function in each iteration\n",
    "def most_central_edge(G):\n",
    "    centrality = betweenness(G, weight='weight')\n",
    "    return max(centrality, key=centrality.get)\n",
    "gn_comm = girvan_newman(main_graph, most_valuable_edge=most_central_edge)\n",
    "\n",
    "# get the communities using girvan newman algorithm\n",
    "first_iteration_comm = tuple(sorted(c) for c in next(gn_comm))\n",
    "\n",
    "# Transform the communities obtained into a dictionary with\n",
    "# key -> communityId\n",
    "# value -> list of nodes in the community\n",
    "gn_dict = dict(enumerate(first_iteration_comm))\n",
    "\n",
    "# Create a dictionary with\n",
    "# key -> product\n",
    "# value -> Id of the community the product belongs to\n",
    "gn_product_comm_dict = {}\n",
    "for comm, products in gn_dict.items():\n",
    "    for product in products:\n",
    "        gn_product_comm_dict[product] = comm\n",
    "\n",
    "# Calculate pagerank for the nodes in each community and create a dictionary where\n",
    "# key -> communityId\n",
    "# value -> list of tuples (product, pagerank) sorted in descending order of pagerank\n",
    "gn_community_pagerank_dict = {}\n",
    "for comm, nodes in gn_dict.items():\n",
    "    page_rank_dict = getPageRankOfCommunity(main_graph, nodes)\n",
    "    gn_community_pagerank_dict[comm] = sorted(page_rank_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "# print(gn_community_pagerank_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return the recommendation of a product using the communities specified\n",
    "# product_comm_dict and community_pagerank_dict can be results of any community detection alorithm (K-clique or girvan-newman)\n",
    "def getProductRecommendations(product, product_comm_dict, community_pagerank_dict):\n",
    "    if product in product_comm_dict:\n",
    "        recommendation_list = []\n",
    "        comm_nodes = community_pagerank_dict[product_comm_dict[product]]\n",
    "        comm_nodes = [(p, pr*cosine_similarity(X_red[list(products_list).index(p)].reshape(1,-1), X_red[list(products_list).index(product)].reshape(1,-1))) for p, pr in comm_nodes]\n",
    "        comm_nodes = sorted(comm_nodes, key=lambda kv: kv[1], reverse=True)\n",
    "        for product_id, pagerank in comm_nodes:\n",
    "            if len(recommendation_list) >= 5:\n",
    "                break\n",
    "            elif product_id != product:\n",
    "                recommendation_list.append(product_id)\n",
    "            else:\n",
    "                continue\n",
    "        return recommendation_list\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict recommendations using communities of K-Clique algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'B004ET7MG8' are: ['B0007NG568', 'B000ER6YO0', 'B000H13270', 'B003ZFRKGO', 'B000HDMUQ2']\n",
      "Recommendations for 'B006K2ZZ7K' are: []\n",
      "Recommendations for 'B0019CW0HE' are: ['B000ER6YO0', 'B003AO5DLO', 'B0009XLVGA', 'B000HKYP9A', 'B0007NG568']\n",
      "Recommendations for 'B000G6RYNE' are: ['B000G6MBX2', 'B001D07IPG', 'B000H13270', 'B0007NG568', 'B000HDMUQ2']\n",
      "Recommendations for 'B000UWSQT0' are: ['B00285FF6O', 'B004X2KR36', 'B000VKYKTG', 'B000IXUISS', 'B0093NIWVO']\n",
      "Recommendations for 'B000G6RYNE' are: ['B000G6MBX2', 'B001D07IPG', 'B000H13270', 'B0007NG568', 'B000HDMUQ2']\n",
      "Recommendations for 'B001LO4ZWI' are: ['B000H13270', 'B0007NG568', 'B000ER6YO0', 'B000HDMUQ2', 'B003ZFRKGO']\n",
      "Recommendations for 'B000ER6YO0' are: ['B000H13270', 'B000G6MBX2', 'B0040WAG7Q', 'B0007NG568', 'B003OB0IB8']\n",
      "Recommendations for 'B000G6RYNE' are: ['B000G6MBX2', 'B001D07IPG', 'B000H13270', 'B0007NG568', 'B000HDMUQ2']\n",
      "Recommendations for 'B000G6RYNE' are: ['B000G6MBX2', 'B001D07IPG', 'B000H13270', 'B0007NG568', 'B000HDMUQ2']\n",
      "Recommendations for 'B001UJEN6C' are: ['B0037LW78C', 'B001ELL9X6', 'B001EO5ZMO', 'B001EPPFGO', 'B000UZMJZO']\n",
      "Recommendations for 'B000G6RYNE' are: ['B000G6MBX2', 'B001D07IPG', 'B000H13270', 'B0007NG568', 'B000HDMUQ2']\n",
      "Recommendations for 'B000G6RYNE' are: ['B000G6MBX2', 'B001D07IPG', 'B000H13270', 'B0007NG568', 'B000HDMUQ2']\n",
      "Recommendations for 'B001EO5QW8' are: []\n",
      "Recommendations for 'B000G6MBX2' are: ['B000H13270', 'B000ER6YO0', 'B0040WAG7Q', 'B003OB0IB8', 'B005YNDIAW']\n",
      "Recommendations for 'B000LQOCH0' are: []\n",
      "Recommendations for 'B000LKZK7C' are: []\n",
      "Recommendations for 'B000G6RYNE' are: ['B000G6MBX2', 'B001D07IPG', 'B000H13270', 'B0007NG568', 'B000HDMUQ2']\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(train_df, test_size=0.02)\n",
    "for product in test_df['product/productId']:\n",
    "    print(\"Recommendations for '\" + product + \"' are: \" + str(getProductRecommendations(product, kc_product_comm_dict, kc_community_pagerank_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict recommendations using communities of Girvan-Newman algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'B004ET7MG8' are: ['B0007NG568', 'B000H13270', 'B000ER6YO0', 'B001EPPFGO', 'B001EO5ZMO']\n",
      "Recommendations for 'B006K2ZZ7K' are: ['B001EO5ZMO', 'B000ER6YO0', 'B003SE19UK', 'B003OB0IB8', 'B004N5KULM']\n",
      "Recommendations for 'B0019CW0HE' are: ['B000ER6YO0', 'B003SE19UK', 'B003AO5DLO', 'B0007NG568', 'B003ZFRKGO']\n",
      "Recommendations for 'B000G6RYNE' are: ['B000H13270', 'B0007NG568', 'B000ER6YO0', 'B001EPPFGO', 'B001EO5ZMO']\n",
      "Recommendations for 'B000UWSQT0' are: ['B000ER6YO0', 'B00285FF6O', 'B001ELL9X6', 'B000LKZK7C', 'B003ZFRKGO']\n",
      "Recommendations for 'B000G6RYNE' are: ['B000H13270', 'B0007NG568', 'B000ER6YO0', 'B001EPPFGO', 'B001EO5ZMO']\n",
      "Recommendations for 'B001LO4ZWI' are: ['B000H13270', 'B0025VRCJY', 'B0007NG568', 'B001EPPFGO', 'B000ER6YO0']\n",
      "Recommendations for 'B000ER6YO0' are: ['B000H13270', 'B003ZFRKGO', 'B0007NG568', 'B001EO5ZMO', 'B000HKYP9A']\n",
      "Recommendations for 'B000G6RYNE' are: ['B000H13270', 'B0007NG568', 'B000ER6YO0', 'B001EPPFGO', 'B001EO5ZMO']\n",
      "Recommendations for 'B000G6RYNE' are: ['B000H13270', 'B0007NG568', 'B000ER6YO0', 'B001EPPFGO', 'B001EO5ZMO']\n",
      "Recommendations for 'B001UJEN6C' are: ['B0037LW78C', 'B000H13270', 'B001EO5ZMO', 'B001ELL9X6', 'B001EPPFGO']\n",
      "Recommendations for 'B000G6RYNE' are: ['B000H13270', 'B0007NG568', 'B000ER6YO0', 'B001EPPFGO', 'B001EO5ZMO']\n",
      "Recommendations for 'B000G6RYNE' are: ['B000H13270', 'B0007NG568', 'B000ER6YO0', 'B001EPPFGO', 'B001EO5ZMO']\n",
      "Recommendations for 'B001EO5QW8' are: ['B0007NG568', 'B000ER6YO0', 'B003ZFRKGO', 'B000LKZK7C', 'B000H13270']\n",
      "Recommendations for 'B000G6MBX2' are: ['B000H13270', 'B000ER6YO0', 'B0007NG568', 'B001EPPFGO', 'B001EO5ZMO']\n",
      "Recommendations for 'B000LQOCH0' are: ['B000LKZK7C', 'B001EPPFGO', 'B0037LW78C', 'B001ELL9X6', 'B000ER6YO0']\n",
      "Recommendations for 'B000LKZK7C' are: ['B001EO5ZMO', 'B003ZFRKGO', 'B001ELL9X6', 'B002BCD2OG', 'B000H13270']\n",
      "Recommendations for 'B000G6RYNE' are: ['B000H13270', 'B0007NG568', 'B000ER6YO0', 'B001EPPFGO', 'B001EO5ZMO']\n"
     ]
    }
   ],
   "source": [
    "for product in test_df['product/productId']:\n",
    "    print(\"Recommendations for '\" + product + \"' are: \" + str(getProductRecommendations(product, gn_product_comm_dict, gn_community_pagerank_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
